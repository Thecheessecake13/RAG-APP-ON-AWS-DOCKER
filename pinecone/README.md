Overview : This is PART 1 
The notebook demonstrates a retrieval-augmented generation (RAG) pipeline using Pinecone as a vector store, Cohere for embeddings, and LangChain for chaining components. 
For Detailed overview of the process, model architecture, and how the generative responses please refer to 'Pinecone_doc.pdf' file. 

NOTE : There are two notebooks here demonstrating usage of Pinecone DB Serverless.


pinecone_hybrid_search.ipynb --------> hybrid search retrieval combination of of Semantic and 
                                              Syntatic searches.


pinecone_ragapp.ipynb ----------> pipeline using Pinecone as a vector store, Cohere for embeddings. 
